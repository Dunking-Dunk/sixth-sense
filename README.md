# 🦯 Sixth Sense: Personal Companion for the Visually Impaired

<p align="center">
  <img src="https://img.shields.io/github/license/Kishorecoder96/sixth-sense" alt="License">
  <img src="https://img.shields.io/github/last-commit/Kishorecoder96/sixth-sense" alt="Last Commit">
  <img src="https://img.shields.io/github/stars/Kishorecoder96/sixth-sense?style=social" alt="GitHub Stars">
  <img src="https://img.shields.io/badge/React_Native-61DAFB?style=flat&logo=react&logoColor=black" alt="React Native">
  <img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Raspberry_Pi-A22846?style=flat&logo=raspberry-pi&logoColor=white" alt="Raspberry Pi">
  <img src="https://img.shields.io/badge/Firebase-FFCA28?style=flat&logo=firebase&logoColor=black" alt="Firebase">
</p>

<p align="center">
  <img src="https://placehold.co/1200x400/6366f1/ffffff?text=Sixth+Sense+AI+Companion" alt="Sixth Sense Banner" style="border-radius: 10px;">
</p>

<p align="center">
  <strong>Empowering navigation, communication, and environmental awareness through AI and hardware integration</strong>
</p>

<p align="center">
  A revolutionary assistive technology that combines cutting-edge AI models with IoT hardware to provide comprehensive support for visually impaired individuals, enhancing their independence and safety in daily life.
</p>

<div align="center">

[🚀 Live Demo](https://www.youtube.com/watch?v=6Zw5p2oYKbo) • [🔧 Hardware Setup](#hardware-components) • [📖 Documentation](#getting-started) • [🐛 Report Issues](https://github.com/Kishorecoder96/sixth-sense/issues)

</div>

---

## 🎯 Project Vision

<div align="center">

### **The Challenge**
**❌ Limited environmental awareness** • **❌ Navigation difficulties** • **❌ Safety concerns** • **❌ Communication barriers**

### **Our Solution**
**✅ AI-powered assistance** • **✅ Real-time guidance** • **✅ Proactive safety alerts** • **✅ Intelligent communication**

</div>

---

## 🚀 About The Project

Sixth Sense represents a groundbreaking approach to assistive technology, combining artificial intelligence, computer vision, and IoT hardware to create a comprehensive personal companion for visually impaired individuals. This innovative system provides real-time environmental awareness, intelligent navigation assistance, and proactive safety monitoring through advanced AI models and sensor integration.

### 🎯 **Core Objectives:**
- **🌍 Environmental Awareness**: Real-time object detection and spatial understanding
- **🗣️ Intelligent Communication**: AI-powered conversational assistant with vision capabilities
- **🧭 Smart Navigation**: GPS-based routing with obstacle avoidance
- **👥 Safety Monitoring**: Fall detection and emergency caregiver alerts
- **🔍 Visual Recognition**: Face detection and text reading capabilities

---

## 🛠️ Technology Arsenal

<div align="center">

### **Complete Technology Stack**

</div>

### 📱 **Frontend Development**

<table>
  <tr>
    <th align="center">Framework</th>
    <th align="center">Platform</th>
    <th align="center">Technology</th>
    <th align="center">Purpose</th>
  </tr>
  <tr>
    <td align="center">
      <img src="https://img.shields.io/badge/React_Native-61DAFB?style=for-the-badge&logo=react&logoColor=black" alt="React Native">
    </td>
    <td align="center">iOS / Android</td>
    <td align="center">Cross-platform</td>
    <td align="center">Caregiver companion app</td>
  </tr>
</table>

### 🔙 **Backend Infrastructure**

<table>
  <tr>
    <th align="center">Service</th>
    <th align="center">Technology</th>
    <th align="center">Purpose</th>
  </tr>
  <tr>
    <td align="center">
      <img src="https://img.shields.io/badge/Firebase-FFCA28?style=for-the-badge&logo=firebase&logoColor=black" alt="Firebase">
    </td>
    <td align="center">Google Cloud</td>
    <td align="center">Real-time database, authentication & hosting</td>
  </tr>
</table>

### 🧠 **AI & Machine Learning Models**

<div align="center">

| AI Model | Provider | Purpose | Implementation |
|:--------:|:--------:|:-------:|:-------------:|
| **Gemini** | Google | Conversational AI assistant | Natural language processing |
| **Gemini Vision Pro** | Google | Advanced image understanding | Visual scene analysis |
| **YOLOv8** | Ultralytics | Real-time object detection | Environment scanning |
| **OpenCV** | Open Source | Computer vision & face recognition | Identity management |
| **EasyOCR** | Open Source | Optical character recognition | Text reading assistance |

</div>

### 💻 **Programming Languages**

<div align="center">

<img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
<img src="https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black" alt="JavaScript">
<img src="https://img.shields.io/badge/C++-00599C?style=for-the-badge&logo=c%2B%2B&logoColor=white" alt="C++">

</div>

### 🔌 **Hardware Components**

<table>
  <tr>
    <th align="center">Component</th>
    <th align="center">Specification</th>
    <th align="center">Purpose</th>
  </tr>
  <tr>
    <td align="center">🖥️ <strong>Raspberry Pi 5</strong></td>
    <td align="center">8GB RAM, Quad-core ARM</td>
    <td align="center">Main processing unit</td>
  </tr>
  <tr>
    <td align="center">🎤 <strong>Microphone</strong></td>
    <td align="center">High-sensitivity audio capture</td>
    <td align="center">Voice input and commands</td>
  </tr>
  <tr>
    <td align="center">📷 <strong>Webcam</strong></td>
    <td align="center">1080p HD with autofocus</td>
    <td align="center">Computer vision and object detection</td>
  </tr>
  <tr>
    <td align="center">🔋 <strong>Power Bank</strong></td>
    <td align="center">20,000 mAh capacity</td>
    <td align="center">Portable power supply</td>
  </tr>
  <tr>
    <td align="center">📍 <strong>GPS Module</strong></td>
    <td align="center">High-precision positioning</td>
    <td align="center">Location tracking and navigation</td>
  </tr>
  <tr>
    <td align="center">⚖️ <strong>Gyroscope Sensor</strong></td>
    <td align="center">3-axis motion detection</td>
    <td align="center">Fall detection and orientation</td>
  </tr>
</table>

---

## ✨ Feature Showcase

<div align="center">

### **Core Capabilities**

| Feature Category | Status | Description |
|:---------------:|:------:|:------------|
| 🌍 **Environmental Awareness** | ✅ Active | Real-time object detection and spatial mapping |
| 🤖 **AI Assistant** | ✅ Active | Intelligent conversational companion |
| 🧭 **Navigation System** | ✅ Active | GPS-based routing with voice guidance |
| 📍 **Live Location Tracking** | ✅ Active | Real-time position sharing with caregivers |
| 🚨 **Alert & Warning System** | ✅ Active | Proactive safety notifications |
| 💬 **Voice Messaging** | ✅ Active | Hands-free communication system |
| 👥 **Caregiver App** | ✅ Active | Remote monitoring and assistance |
| 👤 **Face Recognition** | ✅ Active | Personal identification system |

</div>

---

## 🔍 Advanced AI Features

### 👤 **Face Recognition System**

<div align="center">

```
📷 Camera Detection → 🧠 OpenCV Processing → 📏 Distance Calculation → ⚠️ Safety Alert
```

</div>

**How it works:**
- **Detection Phase**: OpenCV algorithms identify human faces in real-time
- **Distance Analysis**: Calculates proximity using depth estimation techniques
- **Safety Assessment**: Triggers warnings when distance falls below safe thresholds
- **Route Guidance**: Provides alternative path suggestions for safer navigation

### 🚨 **Fall Detection System**

<div align="center">

```
⚖️ Gyroscope Data → 🤖 ML Model → 📊 Pattern Analysis → 🚨 Emergency Alert
```

</div>

**Smart Detection Features:**
- **Real-time Monitoring**: Continuous analysis of motion patterns via Raspberry Pi sensors
- **ML Classification**: Trained neural network distinguishes between normal movement and falls
- **Instant Alerts**: Automatic notification system contacts designated caregivers
- **False Positive Reduction**: Advanced algorithms minimize incorrect fall detections

### 🎯 **Object Detection & Avoidance**

<div align="center">

```
📷 YOLOv8 Scan → 🎯 Object Classification → 📏 Distance Estimation → 🗣️ Voice Guidance
```

</div>

**Advanced Capabilities:**
- **Multi-Object Recognition**: Simultaneously identifies multiple environmental hazards
- **Confidence Scoring**: Reliability metrics for detection accuracy
- **Depth Perception**: Color segmentation and stereo vision for distance calculation
- **Dynamic Warnings**: Contextual alerts based on object type and proximity

### 🗣️ **Intelligent Communication System**

<div align="center">

```
🎤 Speech Input → 📝 Text Conversion → 🧠 AI Processing → 🔊 Voice Response
```

</div>

**Communication Features:**
- **Natural Language Processing**: Gemini-powered conversational AI
- **Visual Understanding**: Gemini Vision Pro for image-based queries
- **Multi-modal Interaction**: Seamless integration of voice, text, and visual inputs
- **Context Awareness**: Maintains conversation history for better assistance

---

## 📱 Mobile Application: Caregiver Companion

<div align="center">

### **Comprehensive Caregiver Dashboard**

| Feature | Description | Technology |
|:-------:|:------------|:----------:|
| 📍 **Real-time Tracking** | Live location monitoring with route history | GPS + Firebase |
| 🚨 **Emergency Alerts** | Instant notifications for falls and emergencies | Push notifications |
| 💬 **Communication Hub** | Direct voice/text messaging with the user | WebRTC + Firebase |
| 📊 **Health Analytics** | Activity patterns and safety metrics | ML analytics |
| ⚙️ **Device Control** | Remote configuration and system management | IoT integration |

</div>

---

## 🚀 Getting Started

### 📋 **Prerequisites Checklist**

<table>
  <tr>
    <td><strong>✅ Software Requirement</strong></td>
    <td><strong>Version</strong></td>
    <td><strong>Installation</strong></td>
  </tr>
  <tr>
    <td>Node.js</td>
    <td>18.0.0+</td>
    <td><a href="https://nodejs.org/">Download Node.js</a></td>
  </tr>
  <tr>
    <td>Python</td>
    <td>3.8+</td>
    <td><a href="https://python.org/">Download Python</a></td>
  </tr>
  <tr>
    <td>React Native CLI</td>
    <td>Latest</td>
    <td><code>npm install -g @react-native-community/cli</code></td>
  </tr>
  <tr>
    <td>Firebase CLI</td>
    <td>Latest</td>
    <td><code>npm install -g firebase-tools</code></td>
  </tr>
</table>

### 📱 **Mobile App Installation**

```bash
# 1️⃣ Clone the repository
git clone https://github.com/Kishorecoder96/sixth-sense.git

# 2️⃣ Navigate to mobile app directory
cd sixth-sense/Mobile_app

# 3️⃣ Install dependencies
npm install

# 4️⃣ Start Metro bundler
npm start

# 5️⃣ Run on device/emulator
# For Android
npx react-native run-android

# For iOS
npx react-native run-ios
```

### 🐍 **Python AI System Setup**

```bash
# 1️⃣ Navigate to AI system directory
cd sixth-sense/AI_System

# 2️⃣ Create virtual environment
python -m venv venv

# 3️⃣ Activate virtual environment
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# 4️⃣ Install Python dependencies
pip install -r requirements.txt

# 5️⃣ Run the main AI system
python main.py
```

### 🔧 **Hardware Setup**

<details>
<summary><strong>🛠️ Raspberry Pi Configuration</strong></summary>

```bash
# 1️⃣ Update Raspberry Pi OS
sudo apt update && sudo apt upgrade -y

# 2️⃣ Install required system packages
sudo apt install python3-pip python3-venv -y

# 3️⃣ Enable camera and GPIO
sudo raspi-config
# Navigate to: Interface Options → Camera → Enable
# Navigate to: Interface Options → GPIO → Enable

# 4️⃣ Install hardware-specific Python packages
pip install RPi.GPIO picamera opencv-python

# 5️⃣ Configure GPIO pins for sensors
# (Refer to hardware_setup.md for detailed wiring)
```

</details>

### 🔑 **Environment Configuration**

<details>
<summary><strong>🔒 API Keys and Configuration</strong></summary>

Create `.env` file in the project root:

```env
# Firebase Configuration
FIREBASE_API_KEY=your_firebase_api_key
FIREBASE_AUTH_DOMAIN=your_project.firebaseapp.com
FIREBASE_PROJECT_ID=your_project_id
FIREBASE_STORAGE_BUCKET=your_project.appspot.com

# Google AI Configuration
GEMINI_API_KEY=your_gemini_api_key
GEMINI_VISION_API_KEY=your_gemini_vision_api_key

# Hardware Configuration
CAMERA_INDEX=0
MICROPHONE_INDEX=1
GPS_SERIAL_PORT=/dev/ttyUSB0
GYROSCOPE_I2C_ADDRESS=0x68

# System Configuration
DEBUG_MODE=false
LOG_LEVEL=INFO
FACE_RECOGNITION_THRESHOLD=0.6
OBJECT_DETECTION_CONFIDENCE=0.5
```

</details>

---

## 📁 Project Architecture

```
sixth-sense/
├── 📱 Mobile_app/               # React Native Caregiver App
│   ├── 📁 src/
│   │   ├── 📁 components/       # Reusable UI components
│   │   ├── 📁 screens/          # Application screens
│   │   ├── 📁 services/         # Firebase and API services
│   │   ├── 📁 utils/            # Utility functions
│   │   ├── 📁 contexts/         # React contexts
│   │   └── 📁 navigation/       ## Navigation configuration
│   ├── 📄 package.json
│   ├── 📄 firebase.json
│   └── 📄 .env
├── 🐍 AI_System/                # Python AI Processing
│   ├── 📁 models/               # ML model files
│   │   ├── 📄 yolov8n.pt        # Object detection model
│   │   ├── 📄 fall_detection.pkl # Fall detection model
│   │   └── 📁 faces/            # Face recognition database
│   ├── 📁 core/                 # Core AI modules
│   │   ├── 📄 object_detection.py
│   │   ├── 📄 face_recognition.py
│   │   ├── 📄 fall_detection.py
│   │   ├── 📄 speech_processing.py
│   │   └── 📄 navigation.py
│   ├── 📁 hardware/             # Hardware interface modules
│   │   ├── 📄 camera_controller.py
│   │   ├── 📄 gps_controller.py
│   │   ├── 📄 gyroscope_controller.py
│   │   └── 📄 audio_controller.py
│   ├── 📁 ai_integration/       # AI model integration
│   │   ├── 📄 gemini_client.py
│   │   ├── 📄 vision_processor.py
│   │   └── 📄 text_processor.py
│   ├── 📁 utils/                # Utility functions
│   │   ├── 📄 config.py
│   │   ├── 📄 logger.py
│   │   └── 📄 helpers.py
│   ├── 📄 main.py               # Main application entry
│   ├── 📄 requirements.txt      # Python dependencies
│   └── 📄 .env                  # Environment variables
├── 📁 docs/                     # Documentation
│   ├── 📄 API.md                # API documentation
│   ├── 📄 HARDWARE_SETUP.md     # Hardware configuration guide
│   ├── 📄 DEPLOYMENT.md         # Deployment instructions
│   └── 📄 USER_GUIDE.md         # User manual
├── 📁 scripts/                  # Automation scripts
│   ├── 📄 setup.sh              # Initial setup script
│   ├── 📄 train_models.py       # Model training script
│   └── 📄 calibrate_sensors.py  # Hardware calibration
├── 📄 README.md                 # This file
├── 📄 LICENSE                   # MIT License
└── 📄 .gitignore               # Git ignore rules
```

---

## 📊 System Performance

<div align="center">

### **Performance Metrics**

| Metric Category | Performance | Target |
|:---------------:|:-----------:|:------:|
| **Object Detection** | 15-20 FPS | >10 FPS |
| **Face Recognition** | <500ms | <1s |
| **Response Time** | <2s | <3s |
| **Battery Life** | 8-10 hours | >6 hours |
| **GPS Accuracy** | ±3 meters | ±5 meters |

</div>

---

## 🔮 Development Roadmap

<div align="center">

### **Current Status: 95% Complete** 

| Phase | Features | Status | Timeline |
|:-----:|:---------|:------:|:--------:|
| **Phase 1** | Core AI features, basic hardware integration | ✅ Complete | Q3 2024 |
| **Phase 2** | Mobile app, Firebase integration | ✅ Complete | Q4 2024 |
| **Phase 3** | Enhanced navigation system | 🚧 In Progress | Q1 2025 |
| **Phase 4** | Advanced ML models, cloud deployment | 📋 Planned | Q2 2025 |

</div>

### 🚀 **Upcoming Enhancements**

**🗺️ Advanced Navigation System**
- Turn-by-turn voice navigation with landmark recognition
- Indoor positioning system using Bluetooth beacons
- Public transportation integration and real-time updates
- Crowdsourced accessibility information for routes

**🤖 Enhanced AI Capabilities**
- Emotion recognition for better user interaction
- Predictive analytics for routine optimization  
- Multi-language support for global accessibility
- Context-aware scene understanding

**🌐 Cloud Integration**
- Real-time model updates and improvements
- Centralized learning from user interactions
- Advanced analytics dashboard for caregivers
- Scalable infrastructure for multiple users

---

## 🧪 Testing & Validation

<div align="center">

### **Testing Framework**

| Test Type | Coverage | Tools | Status |
|:---------:|:--------:|:-----:|:------:|
| **Unit Tests** | >80% | pytest, Jest | ✅ |
| **Integration Tests** | >70% | Custom frameworks | ✅ |
| **Hardware Tests** | >90% | Physical validation | ✅ |
| **User Acceptance** | Ongoing | Beta testing | 🚧 |

</div>

```bash
# Run Python AI system tests
cd AI_System
python -m pytest tests/ -v --cov

# Run React Native app tests  
cd Mobile_app
npm test

# Run hardware integration tests
python scripts/test_hardware.py
```

---

## 🤝 Contributing

<div align="center">

[![Contributors](https://img.shields.io/github/contributors/Kishorecoder96/sixth-sense?style=for-the-badge)](https://github.com/Kishorecoder96/sixth-sense/graphs/contributors)

**Join us in making technology more accessible!**

</div>

### 🚀 **How to Contribute**

1. **🍴 Fork the Repository**
2. **🌿 Create Feature Branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **💻 Make Your Changes**
4. **🧪 Run Tests**
   ```bash
   npm test && python -m pytest
   ```
5. **💾 Commit Changes**
   ```bash
   git commit -m 'Add amazing feature'
   ```
6. **📤 Push to Branch**
   ```bash
   git push origin feature/amazing-feature
   ```
7. **🔀 Open Pull Request**

### 📝 **Contribution Areas**

- **🧠 AI Model Enhancement**: Improve detection accuracy and response times
- **📱 Mobile App Features**: Add new functionality to the caregiver app
- **🔧 Hardware Integration**: Support for additional sensors and devices
- **🌐 Accessibility**: Multi-language support and UI improvements
- **📖 Documentation**: Help make our guides more comprehensive

---

## 📄 License

<div align="center">

[![License](https://img.shields.io/github/license/Kishorecoder96/sixth-sense?style=for-the-badge)](LICENSE)

**This project is licensed under the MIT License** - see the [LICENSE](LICENSE) file for details.

</div>

---

## 🌟 Impact & Recognition

<div align="center">

**Making a difference in the lives of visually impaired individuals worldwide**

### **Project Achievements:**
- 🏆 **95% Functional Prototype** completed and tested
- 👥 **Community Driven** development with accessibility focus  
- 🔬 **Research Grade** AI implementation and validation
- 🌍 **Open Source** contribution to assistive technology

</div>

---

## 📞 Contact & Support

<div align="center">

**Connect with the development team:**

[![GitHub](https://img.shields.io/badge/GitHub-Kishorecoder96-black?style=for-the-badge&logo=github)](https://github.com/Kishorecoder96)
[![Email](https://img.shields.io/badge/Email-Contact-red?style=for-the-badge&logo=gmail&logoColor=white)](mailto:kishorecoder96@gmail.com)

**Project Repository:** [https://github.com/Kishorecoder96/sixth-sense](https://github.com/Kishorecoder96/sixth-sense)

### **Support Channels:**
- 📚 [Documentation](docs/)
- 🐛 [Bug Reports](https://github.com/Kishorecoder96/sixth-sense/issues/new?labels=bug)
- 💡 [Feature Requests](https://github.com/Kishorecoder96/sixth-sense/issues/new?labels=enhancement)
- 💬 [Discussions](https://github.com/Kishorecoder96/sixth-sense/discussions)

</div>

---

<div align="center">

**⭐ If this project inspires you or could help someone you know, please give it a star!**

*Empowering independence through technology* 🦯✨

<a href="#-sixth-sense-personal-companion-for-the-visually-impaired">⬆️ Back to Top</a>

</div>
